{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-08-30T13:30:46.879759Z",
     "iopub.status.busy": "2021-08-30T13:30:46.879372Z",
     "iopub.status.idle": "2021-08-30T13:30:47.920508Z",
     "shell.execute_reply": "2021-08-30T13:30:47.919499Z",
     "shell.execute_reply.started": "2021-08-30T13:30:46.879728Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sklearn.dummy\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-30T13:30:49.06762Z",
     "iopub.status.busy": "2021-08-30T13:30:49.067221Z"
    }
   },
   "outputs": [],
   "source": [
    "#Lecture du Fichier\n",
    "full_df = pd.read_csv('/kaggle/input/retardavionclean/retardAvionClean.csv', index_col=None, sep = '\\t', encoding='UTF-8')\n",
    "full_df.drop({'Unnamed: 0','DEST_CITY_NAME','ORIGIN_CITY_NAME'}, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création d'un échantillon avec 10% des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.random.choice(full_df.shape[0], round(full_df.shape[0]*0.1))\n",
    "sub_df = full_df.iloc[ind]\n",
    "#ind = np.random.choice(df_for_reg_lineaire.shape[0], round(df_for_reg_lineaire.shape[0]*0.1))\n",
    "#suf_df_for_reg_lineaire = df_for_reg_lineaire.iloc[ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du jeu d'entrainement et de test\n",
    "* Utlisation de train_test_split qui va découper les données avec le pourcentage spécifié"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# On récupère les features d'un côté...\n",
    "X = sub_df.drop('ARR_DELAY', axis=1).to_numpy()\n",
    "#X_forReg = suf_df_for_reg_lineaire.drop('ARR_DELAY', axis=1).to_numpy()\n",
    "\n",
    "# et les labels de l'autre\n",
    "y = sub_df[['ARR_DELAY']].to_numpy()\n",
    "#y_forReg = suf_df_for_reg_lineaire[['ARR_DELAY']].to_numpy()\n",
    "\n",
    "#Création d'un jeu d'entrainement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "#X_train_forReg, X_test_forReg, y_train_forReg, y_test_forReg = train_test_split(X_forReg, y_forReg, test_size=0.33)\n",
    "\n",
    "#Suppression des variables temporaires\n",
    "del X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardisation\n",
    "Normalisation et réduction du jeu d'entrainement et du jeu de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création des jeux de données standardisés\n",
    "from sklearn import preprocessing\n",
    "std_scale = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_std = std_scale.transform(X_train)\n",
    "\n",
    "#std_scale = preprocessing.StandardScaler().fit(X_test)\n",
    "X_test_std = std_scale.transform(X_test)\n",
    "\n",
    "#Pour la régression linéaire\n",
    "#std_scale = preprocessing.StandardScaler().fit(X_train_forReg)\n",
    "#X_train_forReg_std = std_scale.transform(X_train_forReg)\n",
    "\n",
    "#std_scale = preprocessing.StandardScaler().fit(X_test_forReg)\n",
    "#X_test_forReg_std = std_scale.transform(X_test_forReg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création de différents modèles\n",
    "## Baseline\n",
    "Création d'un modèle très basique pour avoir une référence basse\n",
    "\n",
    "* Utlisation du modèle DummyRegressort qui ressort la moyenne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sklearn.dummy.DummyRegressor()\n",
    "model.fit(X_train_std, y_train)\n",
    "preds = model.predict(X_test_std)\n",
    "print(sklearn.metrics.r2_score(y_test, preds))\n",
    "print(sklearn.metrics.mean_absolute_error(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CROSS VALIDATION 5FOLDS\n",
    "model = sklearn.dummy.DummyRegressor()\n",
    "sklearn.model_selection.cross_val_score(model, X_train_std, y_train, cv=tscv.split(X_train_std, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indicateurs Regression\n",
    "* explained_variance = metrics.explained_variance_score\n",
    "* max_error = metrics.max_error\n",
    "* neg_mean_absolute_error = metrics.mean_absolute_error\n",
    "* neg_mean_squared_error = metrics.mean_squared_error\n",
    "* neg_root_mean_squared_error = metrics.mean_squared_error\n",
    "* neg_mean_squared_log_error = metrics.mean_squared_log_error\n",
    "* neg_median_absolute_error = metrics.median_absolute_error\n",
    "* R2 = metrics.r2_score\n",
    "* neg_mean_poisson_deviance = metrics.mean_poisson_deviance\n",
    "* neg_mean_gamma_deviance = metrics.mean_gamma_deviance\n",
    "* neg_mean_absolute_percentage_error = metrics.mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction qui consolide les différents modèles dans un tableau avec leurs résultats\n",
    "def consolidationResultat_model(resultat, model, X_test, y_reel , nomModel):\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2 = sklearn.metrics.r2_score(y_reel, y_pred)\n",
    "    mae = sklearn.metrics.mean_absolute_error(y_reel, y_pred)\n",
    "    SqrError = sklearn.metrics.mean_squared_error(y_reel, y_pred)\n",
    "    resultat[nomModel] = {r2,mae,SqrError}\n",
    "    return resultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRID SEARCH pour trouver les HYPERPARAMETRES ==> PAS DANS CET EXEMPLE\n",
    "params = {}\n",
    "model = sklearn.dummy.DummyRegressor()\n",
    "clf = GridSearchCV(model, params, cv=tscv.split(X_train_std, y_train))\n",
    "clf.fit(X_train_std, y_train)\n",
    "consolidationResultat_model(resultat, clf.best_estimator_, X_test_std, y_test,'DummyRegressor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRID SEARCH sur régression linéaire ==> PAS DE PARAMETRE DANS CET EXEMPLE\n",
    "params = {}\n",
    "model = sklearn.linear_model.LinearRegression()\n",
    "clf = GridSearchCV(model, params, cv=tscv.split(X_train_std, y_train))\n",
    "clf.fit(X_train_std, y_train)\n",
    "consolidationResultat_model(resultat, clf.best_estimator_, X_test_std, y_test, 'Régression Linéaire')\n",
    "\n",
    "#Vérifier si une obeservation est complètement aberrante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sklearn.linear_model.LinearRegression()\n",
    "model.fit(X_train_std, y_train)\n",
    "y_pred  = model.predict(X_test_std)\n",
    "\n",
    "print(sklearn.metrics.mean_absolute_error(y_test, y_pred))\n",
    "print(sklearn.metrics.r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(6, 8))\n",
    "plt.barh(full_df.loc[:, full_df.columns != 'ARR_DELAY'].columns.values,model.coef_[0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(full_df.loc[:, full_df.columns != 'ARR_DELAY'].columns.values,model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.suptitle('Prediction/Réel')\n",
    "plt.xlabel('Valeur Réelle')\n",
    "plt.ylabel('Prédiction')\n",
    "plt.scatter(y_test, y_pred,color = 'coral', alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.boxplot(y_train_forReg)\n",
    "plt.ylim(-100,250)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRID SEARCH avec trouver l'Alpha de la régularisation Ridge\n",
    "params = {'alpha':[1, 10]}\n",
    "model = sklearn.linear_model.Ridge()\n",
    "clf = GridSearchCV(model, params, cv=tscv.split(X_train_std, y_train))\n",
    "clf.fit(X_train_std, y_train)\n",
    "consolidationResultat_model(resultat, clf.best_estimator_, X_test_std, y_test, 'Régression Ridge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avantages de l’arbre de régression par rapport au modèle de régression linéaire sont les suivants :\n",
    "* Il est plus simple et plus direct dans son approche\n",
    "* La structure liant Y à X1, . . . , Xp n’importe pas ; celle-ci peut être linéaire ou autre\n",
    "* Il n’y a pas d’hypothèse mathématique sous-jacente (pas d’hypothèse de normalité ou autre)\n",
    "* Les dépendances éventuelles entre X1, . . . , Xp ne posent pas de problème"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRID SEARCH sur arbre de décision\n",
    "params = {'max_depth': range(8, 9, 1)}\n",
    "model = sklearn.tree.DecisionTreeRegressor()\n",
    "clf = GridSearchCV(model, params, cv=tscv.split(X_train_std, y_train))\n",
    "clf.fit(X_train_std, y_train)\n",
    "consolidationResultat_model(resultat, clf.best_estimator_, X_test_std, y_test, 'Arbre de décision')\n",
    "\n",
    "#MAX_DEPTH à 8 semble être le meilleur hyperparamètre\n",
    "#Utiliser les variables les plus importantes features importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sklearn.tree.DecisionTreeRegressor(max_depth = 8)\n",
    "model.fit(X_train_std, y_train)\n",
    "\n",
    "y_pred  = model.predict(X_test_std)\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Prediction/Réel')\n",
    "plt.xlabel('Valeur Réelle')\n",
    "plt.ylabel('Prédiction')\n",
    "plt.scatter(y_test, y_pred,color = 'coral', alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRID SEARCH sur Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "params = {'max_depth': range(8, 14, 2)}\n",
    "model = sklearn.ensemble.RandomForestRegressor(n_estimators = 30)\n",
    "clf = GridSearchCV(model, params, cv=tscv.split(X_train_std, y_train))\n",
    "clf.fit(X_train_std, y_train)\n",
    "consolidationResultat_model(resultat, clf.best_estimator_, X_test_std, y_test, 'RandomForest')\n",
    "\n",
    "#max_depth=10 pour la valeur optimale. Refaire avec n_estimators plus grand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRID SEARCH sur LGBM\n",
    "import lightgbm as lgb\n",
    "params = {\n",
    "    'max_depth': range(13, 16,2)\n",
    "}\n",
    "model = lgb.LGBMRegressor()\n",
    "clf = GridSearchCV(model, params,  cv=tscv.split(X_train_std, y_train))\n",
    "clf.fit(X_train_std, y_train)\n",
    "consolidationResultat_model(resultat, clf.best_estimator_, X_test_std, y_test,'LGBM')\n",
    "#max_depth=15 pour la valeur optimale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRID SEARCH KNN Regressor\n",
    "params = {\n",
    "    'n_neighbors': range(5, 12,1)\n",
    "}\n",
    "model = sklearn.neighbors.KNeighborsRegressor()\n",
    "clf = GridSearchCV(model, params,  cv=tscv.split(X_train_std, y_train))\n",
    "clf.fit(X_train_std, y_train)\n",
    "consolidationResultat_model(resultat, clf.best_estimator_, X_test_std, y_test,'KNN Regressor')\n",
    "\n",
    "#n_neighbors=10 valeur optimale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sklearn.neighbors.KNeighborsRegressor(n_neighbors = 10)\n",
    "model.fit(X_train_std, y_train)\n",
    "y_pred = model.predict(X_test_std)\n",
    "r2 = sklearn.metrics.r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sérialisation du modèle pour le site Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Serialisation du modèle de regression linéaire et du Scaler\n",
    "pickle.dump(model, open('RegressionLineaire.pickle', 'wb')) #Saving the model\n",
    "pickle.dump(std_scale, open('scaler.pickle', 'wb')) #Saving the scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Serialisation du modèle d'arbre de décision\n",
    "pickle.dump(model, open('arbreDecision.pickle', 'wb')) #Saving the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
